{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LqwQO6Kpt-_9",
        "outputId": "f6a331e6-7b84-49f1-8a78-632f59a37538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.20)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Colab에서 필요한 라이브러리 설치\n",
        "pip install mediapipe opencv-python numpy openai python-dotenv\n",
        "apt-get update && apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jv2oxjhwvOds"
      },
      "outputs": [],
      "source": [
        "# 2. 라이브러리 임포트 및 OpenAI API 키 설정\n",
        "import openai\n",
        "from openai import OpenAI # import openai\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import io\n",
        "import json\n",
        "import ast\n",
        "import base64\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93W7uafzvOT8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c3wXcjzo01wQ"
      },
      "outputs": [],
      "source": [
        "# 비디오에서 특정 프레임을 추출하는 함수\n",
        "def read_video_opencv(video_path, frame_indices):\n",
        "    \"\"\"\n",
        "    OpenCV를 사용하여 비디오에서 특정 프레임들을 추출합니다.\n",
        "\n",
        "    Parameters:\n",
        "    - video_path: 비디오 파일 경로\n",
        "    - frame_indices: 추출할 프레임의 인덱스 리스트\n",
        "\n",
        "    Returns:\n",
        "    - 추출된 프레임들의 리스트 (NumPy 배열 형식) 또는 None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"비디오 파일을 열 수 없습니다: {video_path}\")\n",
        "            return None\n",
        "\n",
        "        frames = []\n",
        "        frame_counter = 0\n",
        "        frame_indices_set = set(frame_indices)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_counter in frame_indices_set:\n",
        "                frames.append(frame)\n",
        "                if len(frames) == len(frame_indices):\n",
        "                    break\n",
        "\n",
        "            frame_counter += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if not frames:\n",
        "            print(\"지정된 프레임 인덱스에 해당하는 프레임을 찾을 수 없습니다.\")\n",
        "            return None\n",
        "\n",
        "        return frames\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"비디오에서 프레임 추출 중 오류 발생: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3taEMLJ_9zde"
      },
      "outputs": [],
      "source": [
        "# 비디오 길이 가져오기 함수\n",
        "def get_video_duration(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Could not open video file: {video_path}\")\n",
        "        return None\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "    return duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2_Nv25z698c8"
      },
      "outputs": [],
      "source": [
        "# 비디오에서 프레임 추출 함수\n",
        "def download_and_sample_video_local(video_path, start_time=0, duration=60, frame_interval=3):\n",
        "    \"\"\"\n",
        "    주어진 비디오 파일에서 지정된 시작 시간과 지속 시간 내에서 일정 간격으로 프레임을 추출합니다.\n",
        "\n",
        "    Parameters:\n",
        "    - video_path: 비디오 파일 경로\n",
        "    - start_time: 추출 시작 시간 (초 단위)\n",
        "    - duration: 추출할 구간의 길이 (초 단위)\n",
        "    - frame_interval: 프레임 추출 간격 (초 단위)\n",
        "\n",
        "    Returns:\n",
        "    - 추출된 프레임들의 리스트 (NumPy 배열 형식) 또는 None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # OpenCV로 비디오 캡처\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"비디오 파일을 열 수 없습니다: {video_path}\")\n",
        "            return None\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        if fps == 0:\n",
        "            fps = 30.0  # 기본 FPS 설정\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # 추출할 프레임 인덱스 계산\n",
        "        start_frame = int(start_time * fps)\n",
        "        end_frame = int((start_time + duration) * fps)\n",
        "        frame_indices = list(range(start_frame, end_frame, int(frame_interval * fps)))\n",
        "\n",
        "        frames = []\n",
        "        frame_counter = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_counter in frame_indices:\n",
        "                frames.append(frame)\n",
        "                if len(frames) == len(frame_indices):\n",
        "                    break\n",
        "\n",
        "            frame_counter += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if not frames:\n",
        "            print(\"지정된 프레임 인덱스에 해당하는 프레임을 찾을 수 없습니다.\")\n",
        "            return None\n",
        "\n",
        "        return np.array(frames)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"비디오에서 프레임 추출 중 오류 발생: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q253hdn_2MQj"
      },
      "source": [
        "### 추가 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ACYO9AjduQba"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "\n",
        "# Mediapipe 초기화 (전역 한 번)\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_face = mp.solutions.face_mesh\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "face_mesh = mp_face.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.3, min_tracking_confidence=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gmm_IT28AIET"
      },
      "outputs": [],
      "source": [
        "def calculate_lack_of_eye_contact_score(face_landmarks, frame_width):\n",
        "    \"\"\"\n",
        "    발표자의 시선 부족 정도를 점수로 반환합니다.\n",
        "\n",
        "    Args:\n",
        "        face_landmarks: Mediapipe FaceMesh 랜드마크.\n",
        "        frame_width: 프레임 너비.\n",
        "\n",
        "    Returns:\n",
        "        float: 시선 부족 점수 (0에서 1 사이).\n",
        "    \"\"\"\n",
        "    LEFT_EYE = 33\n",
        "    RIGHT_EYE = 263\n",
        "\n",
        "    # 왼쪽/오른쪽 눈의 x좌표 구하기\n",
        "    left_eye_x = face_landmarks.landmark[LEFT_EYE].x * frame_width\n",
        "    right_eye_x = face_landmarks.landmark[RIGHT_EYE].x * frame_width\n",
        "\n",
        "    # 화면 중앙 범위 설정\n",
        "    center_min = 0.4 * frame_width\n",
        "    center_max = 0.6 * frame_width\n",
        "\n",
        "    # 눈 위치가 화면 중앙에서 얼마나 벗어났는지 계산\n",
        "    left_deviation = max(center_min - left_eye_x, left_eye_x - center_max, 0)\n",
        "    right_deviation = max(center_min - right_eye_x, right_eye_x - center_max, 0)\n",
        "\n",
        "    # 편차를 정규화하여 점수 환산\n",
        "    gaze_score = (left_deviation + right_deviation) / frame_width\n",
        "    return round(min(gaze_score / 0.1, 1.0), 2)  # 소수점 두 자리로 제한"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wsq-IL5-uTSO"
      },
      "outputs": [],
      "source": [
        "def calculate_excessive_gestures_score(hand_landmarks):\n",
        "    \"\"\"\n",
        "    과도한 손동작 정도를 점수로 반환합니다. (엄지와 검지 끝 랜드마크 거리로 예측)\n",
        "\n",
        "    Args:\n",
        "        hand_landmarks: Mediapipe Hands 랜드마크.\n",
        "\n",
        "    Returns:\n",
        "        float: 과도한 제스처 점수 (0에서 1 사이).\n",
        "    \"\"\"\n",
        "    THUMB_TIP = mp_hands.HandLandmark.THUMB_TIP.value\n",
        "    INDEX_TIP = mp_hands.HandLandmark.INDEX_FINGER_TIP.value\n",
        "\n",
        "    # 엄지 끝, 검지 끝 랜드마크 좌표\n",
        "    thumb_tip = hand_landmarks.landmark[THUMB_TIP]\n",
        "    index_tip = hand_landmarks.landmark[INDEX_TIP]\n",
        "\n",
        "    # 두 점 사이의 거리\n",
        "    distance = np.sqrt((thumb_tip.x - index_tip.x) ** 2 + (thumb_tip.y - index_tip.y) ** 2)\n",
        "\n",
        "    # 0.2를 기준으로 1까지 정규화\n",
        "    return round(min(distance / 0.2, 1.0), 2)  # 소수점 두 자리로 제한"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pCeTztehAvda"
      },
      "outputs": [],
      "source": [
        "def calculate_hand_movement_score(current_hand_landmarks, previous_hand_landmarks, threshold=0.1):\n",
        "    \"\"\"\n",
        "    현재 프레임과 이전 프레임에서 손목 위치 변화로 움직임 점수를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        current_hand_landmarks: 현재 프레임의 Mediapipe HandLandmarks 객체.\n",
        "        previous_hand_landmarks: 이전 프레임의 Mediapipe HandLandmarks 객체.\n",
        "        threshold: 움직임 점수 계산 기준이 되는 임계값.\n",
        "\n",
        "    Returns:\n",
        "        float: 움직임 점수 (0에서 1 사이).\n",
        "    \"\"\"\n",
        "    if previous_hand_landmarks is None:\n",
        "        # 이전 프레임 정보가 없으면 움직임 점수를 0으로 반환\n",
        "        return 0.0\n",
        "\n",
        "    WRIST = mp_hands.HandLandmark.WRIST.value\n",
        "    current_wrist = current_hand_landmarks.landmark[WRIST]\n",
        "    previous_wrist = previous_hand_landmarks.landmark[WRIST]\n",
        "\n",
        "    # 손목의 이동 거리 계산\n",
        "    movement_distance = np.sqrt((current_wrist.x - previous_wrist.x)**2 + (current_wrist.y - previous_wrist.y)**2)\n",
        "    # threshold 대비 비율로 점수 환산\n",
        "    movement_score = min(movement_distance / threshold, 1.0)\n",
        "    return round(movement_score, 2)  # 소수점 두 자리로 제한"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rc9vp49PAtv9"
      },
      "outputs": [],
      "source": [
        "def is_hand_out_of_frame(hand_landmarks, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    손이 화면 밖에 위치하는지 여부를 판단합니다.\n",
        "\n",
        "    Args:\n",
        "        hand_landmarks: Mediapipe HandLandmarks 객체.\n",
        "        frame_width: 프레임의 너비.\n",
        "        frame_height: 프레임의 높이.\n",
        "\n",
        "    Returns:\n",
        "        bool: 손이 화면 밖이면 True, 아니면 False.\n",
        "    \"\"\"\n",
        "    for landmark in hand_landmarks.landmark:\n",
        "        x, y = landmark.x * frame_width, landmark.y * frame_height\n",
        "        if x < 0 or x > frame_width or y < 0 or y > frame_height:\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nzxe7htTBBG4"
      },
      "outputs": [],
      "source": [
        "def calculate_head_position_score(pose_landmarks, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    머리(코 위치)의 X, Y 편차로 자세 점수를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        pose_landmarks: Mediapipe Pose 랜드마크.\n",
        "        frame_width: 프레임 너비.\n",
        "        frame_height: 프레임 높이.\n",
        "\n",
        "    Returns:\n",
        "        float: 자세 점수 (0: 좋음 ~ 1: 나쁨).\n",
        "    \"\"\"\n",
        "    NOSE = mp_pose.PoseLandmark.NOSE.value\n",
        "    nose_x = pose_landmarks.landmark[NOSE].x * frame_width\n",
        "    nose_y = pose_landmarks.landmark[NOSE].y * frame_height\n",
        "\n",
        "    # 화면 중심\n",
        "    center_x, center_y = frame_width / 2, frame_height / 2\n",
        "\n",
        "    # X, Y 축 편차 계산\n",
        "    x_distance = abs(nose_x - center_x)\n",
        "    y_distance = abs(nose_y - center_y)\n",
        "\n",
        "    # 최대 허용 거리(정상 자세 범위)\n",
        "    max_x_distance = frame_width * 0.1\n",
        "    max_y_distance = frame_height * 0.2\n",
        "\n",
        "    # X, Y 편차를 정규화하여 점수 계산\n",
        "    x_score = min(x_distance / max_x_distance, 1.0)\n",
        "    y_score = min(y_distance / max_y_distance, 1.0)\n",
        "\n",
        "    # X, Y 평균\n",
        "    posture_score = (x_score + y_score) / 2\n",
        "    return round(posture_score, 2)  # 소수점 두 자리로 제한"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x5C3fyCIuUxy"
      },
      "outputs": [],
      "source": [
        "def calculate_sudden_movement_score(pose_landmarks, previous_pose_landmarks, threshold=0.1):\n",
        "    \"\"\"\n",
        "    갑작스러운 움직임 정도를 점수로 반환합니다.\n",
        "    어깨와 엉덩이의 평균 위치 변화로 추정.\n",
        "\n",
        "    Args:\n",
        "        pose_landmarks: 현재 프레임의 포즈 랜드마크.\n",
        "        previous_pose_landmarks: 이전 프레임의 포즈 랜드마크.\n",
        "        threshold: 움직임 감지 임계값.\n",
        "\n",
        "    Returns:\n",
        "        float: 갑작스러운 움직임 점수 (0에서 1 사이).\n",
        "    \"\"\"\n",
        "    if previous_pose_landmarks is None:\n",
        "        return 0.0\n",
        "\n",
        "    def get_center(landmarks, points):\n",
        "        x = np.mean([landmarks.landmark[p].x for p in points])\n",
        "        y = np.mean([landmarks.landmark[p].y for p in points])\n",
        "        return np.array([x, y])\n",
        "\n",
        "    # 상체 중심 (양 어깨, 양 엉덩이 평균 좌표)\n",
        "    current_center = get_center(pose_landmarks, [\n",
        "        mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
        "        mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
        "        mp_pose.PoseLandmark.LEFT_HIP.value,\n",
        "        mp_pose.PoseLandmark.RIGHT_HIP.value\n",
        "    ])\n",
        "    previous_center = get_center(previous_pose_landmarks, [\n",
        "        mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
        "        mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
        "        mp_pose.PoseLandmark.LEFT_HIP.value,\n",
        "        mp_pose.PoseLandmark.RIGHT_HIP.value\n",
        "    ])\n",
        "\n",
        "    # 현재 상체 중심과 이전 상체 중심 사이의 이동 거리\n",
        "    movement = np.linalg.norm(current_center - previous_center)\n",
        "    return round(min(movement / threshold, 1.0), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e6_u-cYSFjul"
      },
      "outputs": [],
      "source": [
        "def draw_debug_info(frame, pose_landmarks, frame_width, frame_height, posture_score):\n",
        "    \"\"\"\n",
        "    디버깅을 위한 시각화 함수. 코 위치와 화면 중심선을 표시하고 자세 점수를 보여줍니다.\n",
        "\n",
        "    Args:\n",
        "        frame: OpenCV 프레임.\n",
        "        pose_landmarks: Mediapipe Pose 랜드마크.\n",
        "        frame_width: 프레임 너비.\n",
        "        frame_height: 프레임 높이.\n",
        "        posture_score: 계산된 자세 점수.\n",
        "    \"\"\"\n",
        "    NOSE = mp_pose.PoseLandmark.NOSE.value\n",
        "    nose_x = int(pose_landmarks.landmark[NOSE].x * frame_width)\n",
        "    nose_y = int(pose_landmarks.landmark[NOSE].y * frame_height)\n",
        "\n",
        "    # 머리(코) 위치 표시\n",
        "    cv2.circle(frame, (nose_x, nose_y), 5, (0, 255, 0), -1)\n",
        "\n",
        "    # 화면 중심선 그리기\n",
        "    center_x, center_y = frame_width // 2, frame_height // 2\n",
        "    cv2.line(frame, (center_x, 0), (center_x, frame_height), (255, 0, 0), 2)\n",
        "    cv2.line(frame, (0, center_y), (frame_width, center_y), (255, 0, 0), 2)\n",
        "\n",
        "    # 자세 점수 표시\n",
        "    cv2.putText(frame, f\"Posture Score: {posture_score:.2f}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "    # 자세가 매우 나쁘다면 추가 메시지\n",
        "    if posture_score > 0.7:\n",
        "        cv2.putText(frame, \"Poor Posture\", (10, 60),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qrmAU37OLSjG"
      },
      "outputs": [],
      "source": [
        "def calculate_gestures_score(excessive_gestures_score, hand_movement_score):\n",
        "    \"\"\"\n",
        "    손 관련 점수들의 평균을 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        excessive_gestures_score: 과도한 제스처 점수.\n",
        "        hand_movement_score: 손 움직임 점수.\n",
        "\n",
        "    Returns:\n",
        "        float: gestures 점수 (0~1 사이).\n",
        "    \"\"\"\n",
        "    scores = [excessive_gestures_score, hand_movement_score]\n",
        "    return round(sum(scores) / len(scores), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U5jcl_0ALWSr"
      },
      "outputs": [],
      "source": [
        "def is_hand_raised_above_threshold(hand_landmarks, frame_height, threshold_ratio=0.7):\n",
        "    \"\"\"\n",
        "    손이 화면 높이의 특정 비율 이상에 위치하는지 판단합니다.\n",
        "\n",
        "    Args:\n",
        "        hand_landmarks: Mediapipe HandLandmarks 객체.\n",
        "        frame_height: 프레임의 높이.\n",
        "        threshold_ratio: 화면 높이 비율 기준 (기본: 0.7).\n",
        "\n",
        "    Returns:\n",
        "        bool: 손이 기준 높이 이상이면 True, 아니면 False.\n",
        "    \"\"\"\n",
        "    WRIST = mp_hands.HandLandmark.WRIST.value\n",
        "    hand_height = hand_landmarks.landmark[WRIST].y * frame_height\n",
        "    return hand_height < frame_height * (1 - threshold_ratio)  # 위쪽이 0에 가까움"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FYneX8qIDax1"
      },
      "outputs": [],
      "source": [
        "def draw_text(frame, text, x, y, color=(0, 255, 0)):\n",
        "    \"\"\"\n",
        "    프레임 위에 텍스트를 그립니다.\n",
        "\n",
        "    Args:\n",
        "        frame: OpenCV 프레임\n",
        "        text: 표시할 텍스트\n",
        "        x, y: 텍스트 좌표\n",
        "        color: 텍스트 색상 (BGR)\n",
        "    \"\"\"\n",
        "    cv2.putText(frame, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H9eTZpxk8AVE"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_boxes(frame, feedback, pose_landmarks, face_landmarks, hand_landmarks):\n",
        "    \"\"\"\n",
        "    문제 영역에 Bounding Box를 그리고 잘못된 부분을 시각적으로 표시합니다.\n",
        "\n",
        "    Args:\n",
        "        frame: OpenCV 프레임.\n",
        "        feedback: 분석된 피드백 결과 딕셔너리.\n",
        "        pose_landmarks: Mediapipe Pose 랜드마크.\n",
        "        face_landmarks: Mediapipe Face 랜드마크.\n",
        "        hand_landmarks: Mediapipe Hand 랜드마크 리스트.\n",
        "\n",
        "    Returns:\n",
        "        frame: Bounding Box가 추가된 프레임.\n",
        "    \"\"\"\n",
        "    frame_height, frame_width, _ = frame.shape\n",
        "\n",
        "    # 자세 문제 표시\n",
        "    if feedback[\"posture_score\"] > 0.8:\n",
        "        if pose_landmarks:\n",
        "            nose = pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE]\n",
        "            nose_x, nose_y = int(nose.x * frame_width), int(nose.y * frame_height)\n",
        "            cv2.rectangle(frame, (nose_x - 50, nose_y - 50), (nose_x + 50, nose_y + 50), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, \"Posture Issue\", (nose_x - 70, nose_y - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "    # 시선 문제 표시\n",
        "    if feedback[\"gaze_score\"] > 0.5:\n",
        "        if face_landmarks:\n",
        "            left_eye = face_landmarks.landmark[33]  # 왼쪽 눈\n",
        "            right_eye = face_landmarks.landmark[263]  # 오른쪽 눈\n",
        "            left_eye_x, left_eye_y = int(left_eye.x * frame_width), int(left_eye.y * frame_height)\n",
        "            right_eye_x, right_eye_y = int(right_eye.x * frame_width), int(right_eye.y * frame_height)\n",
        "            cv2.rectangle(frame, (left_eye_x - 10, left_eye_y - 10), (right_eye_x + 10, right_eye_y + 10), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, \"Gaze Issue\", (left_eye_x - 50, left_eye_y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # 손 제스처 문제 표시\n",
        "    if feedback[\"gestures_score\"] > 0.5 or feedback[\"hand_raised\"]:\n",
        "        if hand_landmarks:\n",
        "            for hand in hand_landmarks:\n",
        "                wrist = hand.landmark[mp_hands.HandLandmark.WRIST]\n",
        "                wrist_x, wrist_y = int(wrist.x * frame_width), int(wrist.y * frame_height)\n",
        "                cv2.rectangle(frame, (wrist_x - 50, wrist_y - 50), (wrist_x + 50, wrist_y + 50), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, \"Gesture Issue\", (wrist_x - 70, wrist_y - 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # 갑작스러운 움직임 표시\n",
        "    if feedback[\"sudden_movement_score\"] > 0.5:\n",
        "        cv2.putText(frame, \"Sudden Movement Detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 2)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SAeNZ47a8C_r"
      },
      "outputs": [],
      "source": [
        "def process_feedback_and_visualize(frames, feedback_results):\n",
        "    \"\"\"\n",
        "    분석된 피드백 결과를 기반으로 잘못된 부분을 시각적으로 표시합니다.\n",
        "\n",
        "    Args:\n",
        "        frames: 비디오 프레임 리스트.\n",
        "        feedback_results: 각 프레임의 피드백 결과 리스트.\n",
        "\n",
        "    Returns:\n",
        "        processed_frames: Bounding Box와 텍스트가 추가된 프레임 리스트.\n",
        "    \"\"\"\n",
        "    processed_frames = []\n",
        "    for idx, (frame, feedback) in enumerate(zip(frames, feedback_results)):\n",
        "        if feedback[\"frame_index\"] == idx:\n",
        "            pose_landmarks = feedback.get(\"pose_landmarks\", None)\n",
        "            face_landmarks = feedback.get(\"face_landmarks\", None)\n",
        "            hand_landmarks = feedback.get(\"hand_landmarks\", None)\n",
        "            frame = draw_bounding_boxes(frame, feedback, pose_landmarks, face_landmarks, hand_landmarks)\n",
        "            processed_frames.append(frame)\n",
        "    return processed_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cYiPnTWVBoEo"
      },
      "outputs": [],
      "source": [
        "def analyze_frame(frame, previous_pose_landmarks=None, previous_hand_landmarks=None):\n",
        "    \"\"\"\n",
        "    단일 프레임을 분석하여 자세, 시선, 손동작 등의 피드백 정보를 반환합니다.\n",
        "\n",
        "    Args:\n",
        "        frame: 분석할 OpenCV 프레임.\n",
        "        previous_pose_landmarks: 이전 프레임의 포즈 랜드마크 - gestures.\n",
        "        previous_hand_landmarks: 이전 프레임의 손 랜드마크 - gestures.\n",
        "\n",
        "    Returns:\n",
        "        feedback: 분석 결과를 담은 딕셔너리.\n",
        "        current_pose_landmarks: 현재 포즈 랜드마크.\n",
        "        current_hand_landmarks: 현재 손 랜드마크.\n",
        "    \"\"\"\n",
        "    frame_height, frame_width, _ = frame.shape\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Mediapipe 결과 처리\n",
        "    pose_results = pose.process(rgb_frame)\n",
        "    face_results = face_mesh.process(rgb_frame)\n",
        "    hand_results = hands.process(rgb_frame)\n",
        "\n",
        "    # 초기 점수들\n",
        "    posture_score = 0\n",
        "    gaze_score = 0\n",
        "    excessive_gestures_score = 0\n",
        "    sudden_movement_score = 0\n",
        "    hand_out_of_frame_flag = False\n",
        "    hand_movement_score = 0\n",
        "    hand_raised_flag = False  # 손이 너무 높이 올려졌는지 여부\n",
        "\n",
        "    current_pose_landmarks = None\n",
        "    current_hand_landmarks = None\n",
        "\n",
        "    # 포즈 분석\n",
        "    if pose_results.pose_landmarks:\n",
        "        current_pose_landmarks = pose_results.pose_landmarks\n",
        "        posture_score = calculate_head_position_score(current_pose_landmarks, frame_width, frame_height)\n",
        "        sudden_movement_score = calculate_sudden_movement_score(current_pose_landmarks, previous_pose_landmarks)\n",
        "\n",
        "    # 얼굴(시선) 분석\n",
        "    if face_results.multi_face_landmarks:\n",
        "        gaze_score = calculate_lack_of_eye_contact_score(face_results.multi_face_landmarks[0], frame_width)\n",
        "\n",
        "    # 손 분석\n",
        "    if hand_results.multi_hand_landmarks:\n",
        "        for hl in hand_results.multi_hand_landmarks:\n",
        "            # 과도한 제스처 점수 업데이트\n",
        "            g_score = calculate_excessive_gestures_score(hl)\n",
        "            if g_score > excessive_gestures_score:\n",
        "                excessive_gestures_score = g_score\n",
        "\n",
        "            # 손이 화면 밖으로 나갔는지 판정\n",
        "            if is_hand_out_of_frame(hl, frame_width, frame_height):\n",
        "                hand_out_of_frame_flag = True\n",
        "\n",
        "            # 손이 너무 높이 올려졌는지 판정\n",
        "            if is_hand_raised_above_threshold(hl, frame_height):\n",
        "                hand_raised_flag = True\n",
        "\n",
        "            # 이전 손 위치와 비교하여 손 움직임 점수 업데이트\n",
        "            if previous_hand_landmarks is not None:\n",
        "                m_score = calculate_hand_movement_score(hl, previous_hand_landmarks)\n",
        "                if m_score > hand_movement_score:\n",
        "                    hand_movement_score = m_score\n",
        "\n",
        "        # 현재 손 랜드마크 업데이트 (첫 번째 손 기준)\n",
        "        current_hand_landmarks = hand_results.multi_hand_landmarks[0]\n",
        "\n",
        "    # gestures 평균 점수 계산\n",
        "    gestures_score = calculate_gestures_score(excessive_gestures_score, hand_movement_score)\n",
        "\n",
        "    # 피드백 딕셔너리\n",
        "    feedback = {\n",
        "        \"posture_score\": round(posture_score, 2),\n",
        "        \"gaze_score\": round(gaze_score, 2),\n",
        "        \"gestures_score\": gestures_score,  # gestures의 평균 점수\n",
        "        \"sudden_movement_score\": round(sudden_movement_score, 2),\n",
        "        \"hand_out_of_frame\": hand_out_of_frame_flag,\n",
        "        \"hand_raised\": hand_raised_flag  # 손이 너무 높이 올려졌는지 여부\n",
        "    }\n",
        "\n",
        "    return feedback, current_pose_landmarks, current_hand_landmarks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a0IzE3koRQHj"
      },
      "outputs": [],
      "source": [
        "def analyze_video_frames(frames, posture_threshold=0.8, gaze_threshold=0.5,\n",
        "                         gesture_threshold=0.5, movement_threshold=0.5,\n",
        "                         hand_movement_threshold=0.5):\n",
        "    \"\"\"\n",
        "    여러 프레임(영상)을 순차적으로 분석하여 결과를 반환합니다.\n",
        "    각 임계값을 초과하거나 특정 조건(hand_out_of_frame, hand_raised)을 만족하면 프레임과 결과를 추출합니다.\n",
        "\n",
        "    Args:\n",
        "        frames: 분석할 프레임 리스트.\n",
        "        posture_threshold: 자세 불량 판정 기준 점수 - posture_body.\n",
        "        gaze_threshold: 시선 부족 판정 기준 점수 - gaze_processing.\n",
        "        gesture_threshold: 손 제스처 과도 판정 기준 점수 - gestures.\n",
        "        movement_threshold: 갑작스런 움직임 판정 기준 점수 - movement.\n",
        "        hand_movement_threshold: 손 움직임 과도 판정 기준 점수 - gestures.\n",
        "\n",
        "    Returns:\n",
        "        filtered_feedback_results: 기준 초과 또는 조건 만족 피드백 결과 리스트.\n",
        "        filtered_frames: 기준 초과 또는 조건 만족 프레임 리스트.\n",
        "    \"\"\"\n",
        "    filtered_feedback_results = []\n",
        "    filtered_frames = []\n",
        "    previous_pose_landmarks = None\n",
        "    previous_hand_landmarks = None\n",
        "\n",
        "    for idx, frame in enumerate(frames):\n",
        "        # 각 프레임을 분석\n",
        "        feedback, current_pose_landmarks, current_hand_landmarks = analyze_frame(\n",
        "            frame, previous_pose_landmarks, previous_hand_landmarks\n",
        "        )\n",
        "\n",
        "        # 기준 초과 여부 또는 특정 조건 만족 여부 확인\n",
        "        if (feedback[\"posture_score\"] > posture_threshold or\n",
        "            feedback[\"gaze_score\"] > gaze_threshold or\n",
        "            feedback[\"gestures_score\"] > gesture_threshold or\n",
        "            feedback[\"sudden_movement_score\"] > movement_threshold or\n",
        "            feedback[\"hand_out_of_frame\"] or  # 손이 화면 밖으로 나간 경우\n",
        "            feedback[\"hand_raised\"]):         # 손이 너무 높이 올라간 경우\n",
        "\n",
        "            # 기준 초과 또는 조건 만족 프레임 저장\n",
        "            feedback[\"frame_index\"] = idx\n",
        "            filtered_feedback_results.append(feedback)\n",
        "            filtered_frames.append(frame)\n",
        "\n",
        "        # 이전 랜드마크 업데이트\n",
        "        previous_pose_landmarks = current_pose_landmarks if current_pose_landmarks else previous_pose_landmarks\n",
        "        previous_hand_landmarks = current_hand_landmarks if current_hand_landmarks else previous_hand_landmarks\n",
        "\n",
        "    return filtered_feedback_results, filtered_frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFHSvH6J_qJu",
        "outputId": "a1e419d9-fbe4-4ea7-bf4c-97d1517723e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "피드백 결과:\n",
            "{'posture_score': 0.63, 'gaze_score': 0.36, 'gestures_score': 0.0, 'sudden_movement_score': 1.0, 'hand_out_of_frame': False, 'hand_raised': False, 'frame_index': 23}\n",
            "{'posture_score': 0.73, 'gaze_score': 0.57, 'gestures_score': 0.0, 'sudden_movement_score': 0.32, 'hand_out_of_frame': False, 'hand_raised': False, 'frame_index': 24}\n",
            "{'posture_score': 0.53, 'gaze_score': 0.0, 'gestures_score': 0.42, 'sudden_movement_score': 0.91, 'hand_out_of_frame': False, 'hand_raised': False, 'frame_index': 27}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# 비디오 경로 및 출력 디렉토리 설정\n",
        "video_path = \"/content/pr_video_test (1).mp4\"\n",
        "output_dir = \"output_frames\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 프레임 샘플링 함수 호출 (사용자 정의 함수)\n",
        "frames = download_and_sample_video_local(video_path, start_time=0, duration=60, frame_interval=0.5)\n",
        "\n",
        "if frames is not None and len(frames) > 0:\n",
        "    # 비디오 프레임 분석\n",
        "    feedbacks, filtered_frames = analyze_video_frames(frames)\n",
        "\n",
        "    # 조건을 만족하는 결과 프레임 저장\n",
        "    for i, frame in enumerate(filtered_frames):\n",
        "        cv2.imwrite(f\"{output_dir}/frame_{i}.jpg\", frame)\n",
        "\n",
        "    # 피드백 결과 출력\n",
        "    print(\"피드백 결과:\")\n",
        "    for fb in feedbacks:\n",
        "        print(fb)\n",
        "else:\n",
        "    print(\"프레임을 추출할 수 없습니다.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
